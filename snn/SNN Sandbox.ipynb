{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating spiking neurons with Tensorflow\n",
    "\n",
    "In this notebook, we try to simulate a population of spiking neurons using Tensorflow.\n",
    "\n",
    "This exercise is based on an equivalent exercise using [Matlab](http://www.mjrlab.org/wp-content/uploads/2014/05/CSHA_matlab_2012.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking neuron model\n",
    "\n",
    "The neuron model is based on [\"Simple model on spiking neuron\"](http://www.izhikevich.org/publications/spikes.htm), by Eugene M. Izhikevich.\n",
    "\n",
    "<img src=\"izhik.gif\">\n",
    "\n",
    "Electronic version of the figure and reproduction permissions are freely available at www.izhikevich.com\n",
    "\n",
    "The behaviour of the neuron is determined by its membrane potential v that increases over time when it is stimulated by an input current I.\n",
    "Whenever the membrane potential reaches the spiking threshold, the membrane potential is reset.\n",
    "\n",
    "The membrane potential increase is mitigated by an adversary recovery effect defined by the u variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow doesn't support differential equations, so we need to approximate the evolution of the membrane potential and\n",
    "membrane recovery by evaluating their variations over small time intervals dt:\n",
    "\n",
    "dv = 0.04v^2 + 5v + 140 -u + I\n",
    "\n",
    "du = a(bv -u)\n",
    "\n",
    "We can then apply the variations by multiplying by the time interval dt:\n",
    "\n",
    "v += dv.dt\n",
    "\n",
    "u += dv.du\n",
    "    \n",
    "As stated in the model, the 0.04, 5 and 140 values have been defined so that v is in mV, I is in A and t in ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a single neuron with injected current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# A class representing a population of simple neurons\n",
    "#\n",
    "class SimpleNeurons(object):\n",
    "    \n",
    "    def __init__(self, n=1, A=None, B=None, C=None, D=None):\n",
    "\n",
    "        ####################\n",
    "        # Model parameters #\n",
    "        ####################\n",
    "        # Scale of the membrane recovery (lower values lead to slow recovery)\n",
    "        if A is None:\n",
    "            self.A = tf.constant(0.02, shape=[n], dtype=tf.float32)\n",
    "        else:\n",
    "            self.A = A\n",
    "        # Sensitivity of recovery towards membrane potential (higher values lead to higher firing rate)\n",
    "        if B is None:\n",
    "            self.B = tf.constant(0.2, shape=[n], dtype=tf.float32)\n",
    "        else:\n",
    "            self.B = B\n",
    "        # Membrane voltage reset value\n",
    "        if C is None:\n",
    "            self.C = tf.constant(-65.0, shape=[n], dtype=tf.float32)\n",
    "        else:\n",
    "            self.C = C\n",
    "        # Membrane recovery 'boost' after a spike\n",
    "        if D is None:\n",
    "            self.D = tf.constant(8.0, shape=[n], dtype=tf.float32)\n",
    "        else:\n",
    "            self.D = D\n",
    "        # Spiking threshold\n",
    "        self.SPIKING_THRESHOLD = 35.0\n",
    "        # Resting potential\n",
    "        self.RESTING_POTENTIAL = -70.0\n",
    "\n",
    "        ##############################\n",
    "        # Variables and placeholders #\n",
    "        ##############################\n",
    "        # Membrane potential\n",
    "        # All neurons start at the resting potential\n",
    "        self.v = tf.Variable(tf.constant(self.RESTING_POTENTIAL, shape=[n]), name='v')\n",
    "\n",
    "        # Membrane recovery\n",
    "        # All neurons start with a value of B * C\n",
    "        self.u = tf.Variable(self.B*self.C, name='u')\n",
    "\n",
    "        # We need a placeholder to pass the input current\n",
    "        self.I = tf.placeholder(tf.float32, shape=[n])\n",
    "\n",
    "        # We also need a placeholder to pass the length of the time interval\n",
    "        self.dt = tf.placeholder(tf.float32, shape=[n])\n",
    "\n",
    "    #######################################################\n",
    "    # Define the graph of operations to update v and u:   # \n",
    "    # has_fired_op                                        # \n",
    "    #   -> (v_reset_op, u_rest_op)                        #\n",
    "    #      -> (dv_op, du_op)          <- I_op             #\n",
    "    #        -> (v_op, u_op)                              #\n",
    "    # We only need to return the leaf operations as their #\n",
    "    # graph include the others.                           #\n",
    "    #######################################################\n",
    "    def get_ops(self):\n",
    "        \n",
    "        has_fired_op, v_reset_op, u_reset_op = self.get_reset_ops()\n",
    "\n",
    "        I_op = tf.add(self.I, 0.0)\n",
    "        \n",
    "        return self.get_update_ops(has_fired_op, v_reset_op, u_reset_op, I_op)\n",
    "\n",
    "    def get_reset_ops(self):\n",
    "        \n",
    "        # Evaluate which neurons have reached the spiking threshold\n",
    "        has_fired_op = tf.greater_equal(self.v, tf.constant(self.SPIKING_THRESHOLD))\n",
    "    \n",
    "        # Neurons that have spiked must be reset, others simply evolve from their initial value\n",
    "\n",
    "        # Membrane potential is reset to C\n",
    "        v_reset_op = tf.where(has_fired_op, self.C, self.v)\n",
    "\n",
    "        # Membrane recovery is increased by D \n",
    "        u_reset_op = tf.where(has_fired_op, tf.add(self.u, self.D), self.u)\n",
    "\n",
    "        return (has_fired_op, v_reset_op, u_reset_op)\n",
    "        \n",
    "    def get_update_ops(self, has_fired_op, v_reset_op, u_reset_op, I_op):\n",
    "\n",
    "        # Evaluate membrane potential increment for the considered time interval\n",
    "        # dv = 0 if the neuron fired, dv = 0.04v*v + 5v + 140 + I -u otherwise\n",
    "        dv_op = tf.where(has_fired_op,\n",
    "                         tf.zeros(self.v.shape),\n",
    "                         tf.subtract(tf.add_n([tf.multiply(tf.square(v_reset_op), 0.04),\n",
    "                                               tf.multiply(v_reset_op, 5.0),\n",
    "                                               tf.constant(140.0, shape=self.v.shape),\n",
    "                                               I_op]),\n",
    "                                     self.u))\n",
    "            \n",
    "        # Evaluate membrane recovery decrement for the considered time interval\n",
    "        # du = 0 if the neuron fired, du = a*(b*v -u) otherwise\n",
    "        du_op = tf.where(has_fired_op,\n",
    "                         tf.zeros(self.v.shape),\n",
    "                         tf.multiply(self.A, tf.subtract(tf.multiply(self.B, v_reset_op), u_reset_op)))\n",
    "    \n",
    "        # Increment membrane potential, and clamp it to the spiking threshold\n",
    "        # v += dv * dt\n",
    "        v_op = tf.assign(self.v, tf.minimum(tf.constant(self.SPIKING_THRESHOLD, shape=self.v.shape),\n",
    "                                                 tf.add(v_reset_op, tf.multiply(dv_op, self.dt))))\n",
    "\n",
    "        # Decrease membrane recovery\n",
    "        u_op = tf.assign(self.u, tf.add(u_reset_op, tf.multiply(du_op, self.dt)))\n",
    "\n",
    "        return (v_op, u_op)\n",
    "\n",
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Number of neurons\n",
    "n = 1\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = []\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = range(int(T / dt))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Instantiate the population of neuron (here a single one)\n",
    "    neurons = SimpleNeurons(n)\n",
    "    v_op, u_op = neurons.get_ops()\n",
    "\n",
    "    # Initialize global variables to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Run the simulation at each time step\n",
    "    for t in steps:\n",
    "        \n",
    "        # We generate a current step of 7 A between 200 and 700 ms\n",
    "        if t * dt > 200 and t * dt < 700:\n",
    "            i_in = 7.0\n",
    "        else:\n",
    "            i_in = 0.0\n",
    "            \n",
    "        # Create the dictionary of parameters to use for this time step\n",
    "        feed = {neurons.I: np.full((n), i_in), neurons.dt: np.full((n), dt)}\n",
    "        \n",
    "        # Run the graph corresponding to our update ops, passing our parameters\n",
    "        sess.run([v_op, u_op], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        I_in.append(i_in)\n",
    "        v_out.append(neurons.v.eval())\n",
    "\n",
    "# Draw the input current and the membrane potential\n",
    "%matplotlib inline\n",
    "plt.plot([np.asscalar(x) for x in v_out])\n",
    "plt.plot([x for x in I_in])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Simulate a single neuron with synaptic input\n",
    "\n",
    "It is a simple variation of the previous experiment, where the input current is the composition of currents coming from several synapses (typically here, a hundred).\n",
    "\n",
    "The formula for evaluating the synaptic current corresponds to the weighted sum of the input current generated by each synapse:\n",
    "\n",
    "Isyn = Σ w_in(j).Isyn(j)\n",
    "\n",
    "The current Isyn(j) generated by each synapse is the multiplication of:\n",
    "- a linear response to the membrane potential, with a target objective of potential E_in(j): (E_in(j) -v)\n",
    "- a conductance dynamics parameter, that is an exponential function g_in(j) that is defined by a differential equation.\n",
    "\n",
    "dg_in(j)/dt = g_in(j)/tau\n",
    "\n",
    "Each input synapse emits a spike following a poisson distribution of frequency frate. The probability that a neuron fires during the time interval dt is thus frate.dt.\n",
    "\n",
    "To simulate the neuron, we draw random numbers r in the [0,1] interval at each timestep, and is the number r is less than frate.dt, we generate a synapse spike by increasing the conductance dynamics for that synapse:\n",
    "\n",
    "g_in(j) = g_in(j) + 1\n",
    "\n",
    "The complete synaptic current formula at each timestep is:\n",
    "\n",
    "Isyn = Σ w_in(j)g_in(j)(E_in(j) -v(t)) = Σ w_in(j)g_in(j)E_in(j) - (Σ w_in(j)g_in(j)).v(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# A class representing a population of simple neurons with synaptic inputs\n",
    "#\n",
    "class SimpleSynapticNeurons(SimpleNeurons):\n",
    "    \n",
    "    def __init__(self, n=1, m=100, A=None, B=None, C=None, D=None, W_in=None):\n",
    "\n",
    "        # Call the parent contructor\n",
    "        super(SimpleSynapticNeurons, self).__init__(n, A, B, C, D)\n",
    "        \n",
    "        # Additional model parameters\n",
    "        self.tau = 10.0\n",
    "        if W_in is None:\n",
    "            self.W_in = tf.constant(0.07, shape=(n,m), dtype=np.float32)\n",
    "        else:\n",
    "            self.W_in = tf.constant(W_in)\n",
    "        # The reason this one is different is to allow broadcasting when subtracting v\n",
    "        self.E_in = np.zeros((m), dtype=np.float32)\n",
    "        \n",
    "        # Input synapse conductance dynamics (increases on each synapse spike)\n",
    "        self.g_in = tf.Variable(tf.zeros(dtype=tf.float32, shape=[m]),\n",
    "                                dtype=tf.float32,\n",
    "                                name='g_in')\n",
    "\n",
    "        # We need a placeholder to pass the input synapses behaviour at each timestep\n",
    "        self.syn_has_spiked = tf.placeholder(tf.bool, shape=[m])\n",
    "\n",
    "    #######################################################\n",
    "    # Define the graph of operations to update v and u:   # \n",
    "    # has_fired_op                                        # \n",
    "    #   -> (v_reset_op, u_rest_op)      <- g_in_op           #\n",
    "    #      -> (dv_op, du_op)          <- I_op             #\n",
    "    #        -> (v_op, u_op)                              #\n",
    "    # We only need to return the leaf operations as their #\n",
    "    # graph include the others.                           #\n",
    "    #######################################################\n",
    "    def get_ops(self):\n",
    "\n",
    "        # Update the g variable\n",
    "        g_in_op = self.get_input_conductance_ops()\n",
    "\n",
    "        # Get reset ops from parent model\n",
    "        has_fired_op, v_reset_op, u_reset_op = self.get_reset_ops()\n",
    "\n",
    "        # We can now evaluate the synaptic input currents\n",
    "        # Isyn = Σ w_in(j)g_in(j)E_in(j) - (Σ w_in(j)g_in(j)).v(t)\n",
    "        I_op = tf.subtract(tf.einsum('nm,m->n', self.W_in, tf.multiply(g_in_op, self.E_in)),\n",
    "                           tf.multiply(tf.einsum('nm,m->n', self.W_in, g_in_op), v_reset_op))\n",
    "        \n",
    "        # Finally, get v and u update operations\n",
    "        v_op, u_op = self.get_update_ops(has_fired_op, v_reset_op, u_reset_op, I_op)\n",
    "        \n",
    "        return (g_in_op, v_op, u_op)\n",
    "    \n",
    "    def get_input_conductance_ops(self):\n",
    "\n",
    "        # First, update synaptic conductance dynamics:\n",
    "        # - increment by one the current factor of synapses that fired\n",
    "        # - decrease by tau the conductance dynamics in any case\n",
    "        g_in_update_op = tf.where(self.syn_has_spiked,\n",
    "                                  tf.add(self.g_in, tf.ones(shape=self.g_in.shape)),\n",
    "                                  tf.subtract(self.g_in, tf.divide(self.g_in, self.tau)))\n",
    "\n",
    "        # Update the g variable\n",
    "        g_in_op = tf.assign(self.g_in, g_in_update_op)\n",
    "\n",
    "        return g_in_op\n",
    "\n",
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = []\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = range(int(T / dt))\n",
    "# Number of neurons\n",
    "n = 1\n",
    "# Number of synapses\n",
    "m = 100\n",
    "# Synapses firing rate\n",
    "frate = 0.002\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Instantiate the population of synaptic neurons\n",
    "    neurons = SimpleSynapticNeurons(n, m)\n",
    "\n",
    "    # Initialize v and u to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # build the graph allowing us to update both v and u\n",
    "    g_in_out_op, v_out_op, u_out_op = neurons.get_ops()\n",
    "\n",
    "    # Run the simulation at each time step\n",
    "    for t in steps:\n",
    "        \n",
    "        # We generate random spikes on the input synapses between 200 and 700 ms\n",
    "        if t * dt > 200 and t * dt < 700:\n",
    "            # Generate a random matrix\n",
    "            r = np.random.uniform(0,1,(m))\n",
    "            # A synapse has spiked when r is lower than the spiking rate\n",
    "            p_syn_spike = r < frate * dt\n",
    "        else:\n",
    "            # No synapse activity during that period\n",
    "            p_syn_spike = np.zeros((m), dtype=bool)\n",
    "        \n",
    "        feed = {neurons.syn_has_spiked: p_syn_spike, neurons.dt: np.full((n), dt)}\n",
    "\n",
    "        # Run the graph corresponding to our update ops, with our parameters \n",
    "        sess.run([g_in_out_op, v_out_op, u_out_op], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        v_out.append(neurons.v.eval())\n",
    "\n",
    "# Draw the input current and the membrane potential\n",
    "%matplotlib inline\n",
    "plt.plot([np.asscalar(x) for x in v_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Simulate 1000 neurons with synaptic input\n",
    "\n",
    "Each neuron is either inhibitory (a=0.1, d=2.0) or excitatory (a=0.02, d=8.0), with a proportion of 20% inhibitory.\n",
    "\n",
    "We therefore define a random uniform vector p on[0,1], and condition the a and d vectors of our neuron population on p.\n",
    "\n",
    "a[p<0.2] = 0.1, a[p >=0.2] = 0.02\n",
    "\n",
    "d[p<0.2] = 2.0, d[p >=0.2] = 8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Number of neurons\n",
    "n = 1000\n",
    "# Number of synapses\n",
    "m = 100\n",
    "# Synapses firing rate\n",
    "frate = 0.002\n",
    "\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = np.zeros((steps,n))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Generate a random distribution for our neurons\n",
    "    p_neurons = np.random.uniform(0,1,(n))\n",
    "    \n",
    "    # Assign neuron parameters based on the probability\n",
    "    a = np.full((n), 0.02, dtype=np.float32)\n",
    "    a[p_neurons < 0.2] = 0.1\n",
    "    d = np.full((n), 8.0, dtype=np.float32)\n",
    "    d[p_neurons < 0.2] = 2.0\n",
    "    \n",
    "    # Randomly connect 10% of the neurons to the input synapses\n",
    "    p_syn = np.random.uniform(0,1,(n,m))\n",
    "    w_in = np.zeros((n,m), dtype=np.float32)\n",
    "    w_in[ p_syn < 0.1 ] = 0.07\n",
    "    \n",
    "    # Instantiate the population of synaptic neurons\n",
    "    neurons = SimpleSynapticNeurons(n, m, A=a, D=d, W_in=w_in)\n",
    "\n",
    "    # Initialize global variables to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # build the graph allowing us to update both v and u\n",
    "    g_out_op, v_out_op, u_out_op = neurons.get_ops()\n",
    "\n",
    "    # Run the simulation at each time step\n",
    "    for t in range(steps):\n",
    "        \n",
    "        # We generate random spikes on the input synapses between 200 and 700 ms\n",
    "        if t * dt > 200 and t * dt < 700:\n",
    "            # Generate a random matrix\n",
    "            r = np.random.uniform(0,1,(m))\n",
    "            # A synapse has spiked when r is lower than the spiking rate\n",
    "            p_syn_spike = r < frate * dt\n",
    "        else:\n",
    "            # No synapse activity during that period\n",
    "            p_syn_spike = np.zeros((m), dtype=bool)\n",
    "        \n",
    "        feed = {neurons.syn_has_spiked: p_syn_spike, neurons.dt: np.full((n), dt)}\n",
    "\n",
    "        # Run the graph corresponding to our update ops, with our parameters \n",
    "        sess.run([g_out_op, v_out_op, u_out_op], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        v_out[t, :] = neurons.v.eval()\n",
    "\n",
    "# Split between inhibitory and excitatory\n",
    "inh_v_out = np.where(p_neurons < 0.2, v_out, 0)\n",
    "exc_v_out = np.where(p_neurons >= 0.2, v_out, 0)\n",
    "# Identify spikes\n",
    "inh_spikes = np.argwhere(inh_v_out == 35.0)\n",
    "exc_spikes = np.argwhere(exc_v_out == 35.0)\n",
    "# Display spikes over time\n",
    "plt.axis([0, T, 0, n])\n",
    "plt.title('Inhibitory and excitatory spikes')\n",
    "# Plot inhibitory spikes\n",
    "steps, neurons = inh_spikes.T\n",
    "plt.scatter(steps*dt, neurons, s=3)\n",
    "# Plot excitatory spikes\n",
    "steps, neurons = exc_spikes.T\n",
    "plt.scatter(steps*dt, neurons, s=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Simulate 1000 neurons with recurrent connections\n",
    "\n",
    "A neuron i is sparsely (with probability prc = 0.1) connected to a neuron j.\n",
    "\n",
    "Thus neuron i receives an additional current Isyn(i) of the same form as the synaptic input:\n",
    "\n",
    "Isyn = Σ w(ij)g(j)(E(j) -v(t))\n",
    "\n",
    "Weights w are Gamma distributed (scale 0.003, shape 2).\n",
    "\n",
    "Inhibitory to excitatory connections are twice as strong.\n",
    "\n",
    "E(j) is set to -85 for inhibitory neurons, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# A class representing a population of simple neurons with synaptic inputs\n",
    "#\n",
    "class SimpleSynapticRecurrentNeurons(SimpleSynapticNeurons):\n",
    "    \n",
    "    def __init__(self, n=1, m=100, A=None, B=None, C=None, D=None, W_in=None, W=None, E=None):\n",
    "\n",
    "        # Call the parent contructor\n",
    "        super(SimpleSynapticRecurrentNeurons, self).__init__(n, m, A, B, C, D, W_in)\n",
    "                \n",
    "        # Recurrent synapse conductance dynamics (increases on each synapse spike)\n",
    "        self.g = tf.Variable(tf.zeros(dtype=tf.float32, shape=[n]),\n",
    "                             dtype=tf.float32,\n",
    "                             name='g')\n",
    "        \n",
    "        self.W = tf.constant(W)\n",
    "        self.E = tf.constant(E)\n",
    "\n",
    "    #######################################################\n",
    "    # Define the graph of operations to update v and u:   # \n",
    "    # has_fired_op                                        # \n",
    "    #   -> (v_reset_op, u_rest_op)      <- (g_in_op, g_op)#\n",
    "    #      -> (dv_op, du_op)          <- I_op             #\n",
    "    #        -> (v_op, u_op)                              #\n",
    "    # We only need to return the leaf operations as their #\n",
    "    # graph include the others.                           #\n",
    "    #######################################################\n",
    "    def get_ops(self):\n",
    "\n",
    "        has_fired_op = tf.greater_equal(self.v, tf.constant(self.SPIKING_THRESHOLD))\n",
    "        # First, update recurrent conductance dynamics:\n",
    "        # - increment by one the current factor of synapses that fired\n",
    "        # - decrease by tau the conductance dynamics in any case\n",
    "        g_update_op = tf.where(has_fired_op,\n",
    "                               tf.add(self.g, tf.ones(shape=self.g.shape)),\n",
    "                               tf.subtract(self.g, tf.divide(self.g, self.tau)))\n",
    "\n",
    "        # Update the g variable\n",
    "        g_op = tf.assign(self.g, g_update_op)\n",
    "\n",
    "        # Get input conductance dynamics from parent\n",
    "        g_in_op = self.get_input_conductance_ops()\n",
    "\n",
    "        # Get reset ops from parent model\n",
    "        has_fired_op, v_reset_op, u_reset_op = self.get_reset_ops()\n",
    "\n",
    "        # We can now evaluate the recurrent conductance\n",
    "        # I_rec = Σ wjgj(Ej -v(t))\n",
    "        I_rec_op = tf.einsum('ij,j->i', self.W, tf.multiply(g_op, tf.subtract(self.E, v_reset_op)))\n",
    "\n",
    "        # And the input conductance\n",
    "        # Isyn = Σ w_in(j)g_in(j)E_in(j) - (Σ w_in(j)g_in(j)).v(t)\n",
    "        I_in_op = tf.subtract(tf.einsum('nm,m->n', self.W_in, tf.multiply(g_in_op, self.E_in)),\n",
    "                              tf.multiply(tf.einsum('nm,m->n', self.W_in, g_in_op), v_reset_op))\n",
    "        \n",
    "        # Evaluate the total current\n",
    "        I_op = tf.add(I_rec_op, I_in_op)\n",
    "\n",
    "        # Finally, get v and u update operations\n",
    "        v_op, u_op = self.get_update_ops(has_fired_op, v_reset_op, u_reset_op, I_op)\n",
    "        \n",
    "        return (g_op, g_in_op, v_op, u_op)\n",
    "\n",
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Number of neurons\n",
    "n = 1000\n",
    "# Number of synapses\n",
    "m = 100\n",
    "# Synapses firing rate\n",
    "frate = 0.002\n",
    "\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = np.zeros((steps,n))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Generate a random distribution for our neurons\n",
    "    p_neurons = np.random.uniform(0,1,(n))\n",
    "    \n",
    "    # Assign neuron parameters based on the probability\n",
    "    a = np.full((n), 0.02, dtype=np.float32)\n",
    "    a[p_neurons < 0.2] = 0.1\n",
    "    d = np.full((n), 8.0, dtype=np.float32)\n",
    "    d[p_neurons < 0.2] = 2.0\n",
    "\n",
    "    # Randomly connect 10% of the neurons to the input synapses\n",
    "    p_syn = np.random.uniform(0,1,(n,m))\n",
    "    w_in = np.zeros((n,m), dtype=np.float32)\n",
    "    w_in[ p_syn < 0.1 ] = 0.07\n",
    "    \n",
    "    # Randomly distribute recurrent connections\n",
    "    w = np.zeros((n,n),  dtype=np.float32)\n",
    "    p_reccur = np.random.uniform(0,1,(n,n))\n",
    "    w[p_reccur < 0.1] = np.random.gamma(2, 0.003)\n",
    "    # Identify inhibitory to excitatory connections (receiving end is in row)\n",
    "    inh_2_exc = np.ix_(p_neurons >= 0.2, p_neurons < 0.2)\n",
    "    # Increase the strength of these connections\n",
    "    w[ inh_2_exc ] = 2* w[ inh_2_exc]\n",
    "\n",
    "    # Only inhibitory neurons have E=-85 mv\n",
    "    e = np.zeros((n), dtype=np.float32)\n",
    "    e[p_neurons<0.2] = -85.0\n",
    "\n",
    "    # Instantiate the population of synaptic neurons\n",
    "    neurons = SimpleSynapticRecurrentNeurons(n, m, A=a, D=d, W_in=w_in, W=w, E=e)\n",
    "\n",
    "    # Initialize v and u to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # build the graph allowing us to update both v and u\n",
    "    g_out_op, g_in_out_op, v_out_op, u_out_op = neurons.get_ops()\n",
    "\n",
    "    # Run the simulation at each time step\n",
    "    for t in range(steps):\n",
    "        \n",
    "        # We generate random spikes on the input synapses between 200 and 700 ms\n",
    "        if t * dt > 200 and t * dt < 700:\n",
    "            # Generate a random matrix\n",
    "            r = np.random.uniform(0,1,(m))\n",
    "            # A synapse has spiked when r is lower than the spiking rate\n",
    "            p_syn_spike = r < frate * dt\n",
    "        else:\n",
    "            # No synapse activity during that period\n",
    "            p_syn_spike = np.zeros((m), dtype=bool)\n",
    "        \n",
    "        feed = {neurons.syn_has_spiked: p_syn_spike, neurons.dt: np.full((n), dt)}\n",
    "\n",
    "        # Run the graph corresponding to our update ops, with our parameters \n",
    "        sess.run([g_out_op, g_in_out_op, v_out_op, u_out_op], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        v_out[t, :] = neurons.v.eval()\n",
    "\n",
    "# Split between inhibitory and excitatory\n",
    "inh_v_out = np.where(p_neurons < 0.2, v_out, 0)\n",
    "exc_v_out = np.where(p_neurons >= 0.2, v_out, 0)\n",
    "# Identify spikes\n",
    "inh_spikes = np.argwhere(inh_v_out == 35.0)\n",
    "exc_spikes = np.argwhere(exc_v_out == 35.0)\n",
    "# Display spikes over time\n",
    "plt.axis([0, T, 0, n])\n",
    "plt.title('Inhibitory and excitatory spikes')\n",
    "# Plot inhibitory spikes\n",
    "steps, neurons = inh_spikes.T\n",
    "plt.scatter(steps*dt, neurons, s=2)\n",
    "# Plot excitatory spikes\n",
    "steps, neurons = exc_spikes.T\n",
    "plt.scatter(steps*dt, neurons, s=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
